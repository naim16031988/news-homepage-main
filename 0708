# 1. Upload your CSV
from google.colab import files
uploaded = files.upload()

# 2. Imports
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from statsmodels.tsa.arima.model import ARIMA
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from math import sqrt

# 3. Load and preprocess
filename = list(uploaded.keys())[0]
df = pd.read_csv(filename)
df['timestamp'] = pd.to_datetime(df['timestamp'])
df = df.sort_values('timestamp')
df = df.set_index('timestamp')
df = df.asfreq('20S')  # adjust if different
df['cpu'] = df['cpu'].astype(float)

# 4. ARMA rolling forecast evaluation
def evaluate_arma_over_windows(df, max_window_size=30, prediction_horizon=180):
    results = []
    for window_size in range(3, max_window_size + 1):
        y_true, y_pred = [], []
        for i in range(window_size, len(df) - prediction_horizon):
            train_series = df['cpu'].iloc[i - window_size:i]
            try:
                model = ARIMA(train_series, order=(3, 0, 0))
                model_fit = model.fit()
                forecast = model_fit.forecast(steps=prediction_horizon)
                pred = forecast[-1]
                actual = df['cpu'].iloc[i + prediction_horizon]
                y_true.append(actual)
                y_pred.append(pred)
            except:
                continue
        if y_true:
            mape = np.mean(np.abs((np.array(y_true) - np.array(y_pred)) / np.maximum(np.abs(y_true), 1e-5))) * 100
            rmse = sqrt(mean_squared_error(y_true, y_pred))
            r2 = r2_score(y_true, y_pred)
            results.append({
                "window_size": window_size,
                "MAPE": mape,
                "RMSE": rmse,
                "R2": r2
            })
    return pd.DataFrame(results)

# 5. Plot for different horizons
horizons = [60, 120, 180, 240, 300, 360]
fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(18, 10))
axes = axes.flatten()

for idx, horizon in enumerate(horizons):
    print(f"Evaluating for horizon: {horizon} sec")
    results_df = evaluate_arma_over_windows(df, max_window_size=30, prediction_horizon=horizon // 20)
    ax = axes[idx]
    ax.plot(results_df['window_size'], results_df['MAPE'], label='MAPE', marker='o')
    ax.plot(results_df['window_size'], results_df['RMSE'], label='RMSE', marker='o')
    ax.plot(results_df['window_size'], results_df['R2'], label='R² Score', marker='o')
    ax.set_title(f'Horizon = {horizon}s')
    ax.set_xlabel("Window Size")
    ax.set_ylabel("Error / Score")
    ax.grid(True)
    ax.legend()

plt.tight_layout()
plt.show()o









import paramiko

def configure_docker_remote_api(host, username, key_path=None, password=None):
    commands = [
        # 1. Create directory
        "sudo mkdir -p /etc/systemd/system/docker.service.d",
        # 2. Create override.conf with the required ExecStart
        """echo -e '[Service]\\nExecStart=\\nExecStart=/usr/bin/dockerd -H unix:///var/run/docker.sock -H tcp://0.0.0.0:2375' | sudo tee /etc/systemd/system/docker.service.d/override.conf""",
        # 3. Reload systemd and restart Docker
        "sudo systemctl daemon-reexec",
        "sudo systemctl daemon-reload",
        "sudo systemctl restart docker"
    ]

    print(f"🔐 Connecting to {host}...")
    ssh = paramiko.SSHClient()
    ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
    
    try:
        if key_path:
            ssh.connect(hostname=host, username=username, key_filename=key_path)
        else:
            ssh.connect(hostname=host, username=username, password=password)
        
        for cmd in commands:
            print(f"🛠️ Executing: {cmd}")
            stdin, stdout, stderr = ssh.exec_command(cmd)
            exit_code = stdout.channel.recv_exit_status()
            if exit_code == 0:
                print(stdout.read().decode().strip())
            else:
                print(f"❌ Error in: {cmd}\n{stderr.read().decode()}")
                break

        print("✅ Docker API configured on port 2375 (insecure)")
    finally:
        ssh.close()

# Example usage
if __name__ == "__main__":
    configure_docker_remote_api(
        host="192.168.122.101",    # 🔁 Replace with your VM IP
        username="your_user",      # 🔁 Replace with remote username
        key_path="/path/to/id_rsa" # or use password="your_password"
    )



import os
import requests
import json

DOCKER_HOST = "http://192.168.122.101:2375"
DEFAULT_DISPLAY = os.environ.get("DISPLAY", ":0")
XAUTH = os.path.expanduser("~/.Xauthority")

def create_container(container_name, image_name, port):
    url = f"{DOCKER_HOST}/containers/create?name={container_name}"
    headers = {"Content-Type": "application/json"}

    config = {
        "Image": image_name,
        "Env": [
            f"DISPLAY={DEFAULT_DISPLAY}",
            f"PORT={port}",
            "XAUTHORITY=/root/.Xauthority"
        ],
        "HostConfig": {
            "NetworkMode": "host",
            "NanoCpus": 3000000000,  # 3 CPUs = 3 * 1e9 nanocpus
            "Binds": [
                "/tmp/.X11-unix:/tmp/.X11-unix",
                f"{XAUTH}:/root/.Xauthority"
            ]
        }
    }

    # 1. Création du conteneur
    res = requests.post(url, headers=headers, data=json.dumps(config))
    if res.status_code != 201:
        print("❌ Failed to create container:", res.text)
        return None
    container_id = res.json()["Id"]
    print(f"✅ Container created: {container_id}")

    # 2. Démarrage du conteneur
    start_url = f"{DOCKER_HOST}/containers/{container_id}/start"
    start = requests.post(start_url)
    if start.status_code == 204:
        print("🚀 Container started")
    else:
        print("❌ Failed to start container:", start.text)

if __name__ == "__main__":
    create_container(
        container_name="my_app",
        image_name="your_image_name",
        port="8081"
    )




@app.route('/get_vm_to_scale_down', methods=['GET'])
def get_vm_to_scale_down():
    global last_state, last_action, last_energy, last_time

    container_counts = get_container_count(prometheus_url)
    max_index = container_counts.index(max(container_counts))
    vm_ip_to_remove = vm_ips[max_index]

    # Update the container count BEFORE computing next state
    container_counts[max_index] -= 1
    next_state = build_state(container_counts)

    if last_state is not None and last_action is not None and last_energy is not None and last_time is not None:
        current_energy = get_average_power_from_hosts(host_ips)
        current_time = time.time()
        delta_energy = current_energy - last_energy
        delta_time = current_time - last_time

        if delta_time != 0:
            power_watts = delta_energy / (delta_time * 1_000_000)
            reward = -power_watts
            print("Updating Q-table for scale-down")
            update_q_table(last_state, last_action, reward, next_state, len(container_counts))

    print(f"return this: {vm_ip_to_remove}")
    return jsonify({
        "scaled_down_vm_ip": vm_ip_to_remove,
        "message": "Selected most saturated VM"
    })






max_index = c





ontainer_counts.index(max(container_counts))
vm_ip_to_remove = vm_ips[max_index]

container_counts[max_index] -= 1  # MUST be done before computing next_state
next_state = build_state(container_counts)

if last_state is not None  last_action is not None and last_energy is not None and last_time is not None:
    current_energy = get_average_power_from_hosts(host_ips)
    current_time = time.time()
    delta_energy = current_energy - last_energy
    delta_time = current_time - last_time
    if delta_time > 0:
        power_watts = delta_energy / (delta_time * 1_000_000)
        reward = -power_watts
        print("Updating Q-table for scale-down")
        update_q_table(last_state, last_action, reward, next_state, len(container_counts))



import zmq
import cv2
import numpy as np
import threading

# List of ports your detectors are sending on
DETECTOR_PORTS = [5557, 5558]

# Store latest frame from any detector
latest_frame = None
lock = threading.Lock()

def receive_from_detector(port):
    global latest_frame
    context = zmq.Context()
    socket = context.socket(zmq.PULL)
    socket.connect(f"tcp://localhost:{port}")
    print(f"[Viewer] Connected to detector on port {port}")

    while True:
        try:
            frame_bytes = socket.recv()
            npimg = np.frombuffer(frame_bytes, dtype=np.uint8)
            frame = cv2.imdecode(npimg, 1)

            with lock:
                latest_frame = frame

        except Exception as e:
            print(f"[Viewer] Error receiving from port {port}: {e}")

# Start a thread for each detector connection
for port in DETECTOR_PORTS:
    t = threading.Thread(target=receive_from_detector, args=(port,), daemon=True)
    t.start()

# Display loop
cv2.namedWindow("Unified Viewer", cv2.WINDOW_NORMAL)
cv2.resizeWindow("Unified Viewer", 960, 540)

while True:
    with lock:
        if latest_frame is not None:
            cv2.imshow("Unified Viewer", latest_frame)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cv2.destroyAllWindows()
# Global writer, initialized only once
video_writer = None
output_path = "annotated_output.avi"
fourcc = cv2.VideoWriter_fourcc(*'XVID')
fps = 20  # You can adjust this

cv2.namedWindow("YOLOv5 Reconstructed", cv2.WINDOW_NORMAL)
cv2.resizeWindow("YOLOv5 Reconstructed", 960, 540)

while True:
    if expected_frame_id in frame_buffer:
        frame = frame_buffer.pop(expected_frame_id)

        # Initialize writer when first frame arrives
        if video_writer is None:
            h, w = frame.shape[:2]
            video_writer = cv2.VideoWriter(output_path, fourcc, fps, (w, h))
            print(f"[INFO] Saving video to: {output_path}")

        # Write frame to video file
        video_writer.write(frame)

        # Display frame
        cv2.imshow("YOLOv5 Reconstructed", frame)
        expected_frame_id += 1

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Clean up
if video_writer:
    video_writer.release()
cv2.destroyAllWindows()





import cv2

video_path = "annotated_output.avi"  # or .mp4 depending on your output

cap = cv2.VideoCapture(video_path)

if not cap.isOpened():
    print("❌ Could not open video file.")
    exit()

while True:
    ret, frame = cap.read()
    if not ret:
        break

    cv2.imshow("Saved Annotated Video", frame)

    if cv2.waitKey(25) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()










def receive_from_vm(ip, port, stop_event):
    sock = context.socket(zmq.PULL)
    sock.connect(f"tcp://{ip}:{port}")
    print(f"[INFO] Connected to detector at {ip}:{port}")
    
    while not stop_event.is_set():
        try:
            msg = sock.recv(flags=zmq.NOBLOCK)
            data = msgpack.unpackb(msg, raw=False)
            frame_id = data["frame_id"]
            jpg = data["image"]
            print(f"frame id :{frame_id} with size: {len(msg)} received from VM {ip}")
            frame = cv2.imdecode(np.frombuffer(jpg, np.uint8), cv2.IMREAD_COLOR)
            if frame is not None:
                frame_buffer[frame_id] = frame
        except zmq.Again:
            time.sleep(0.01)
        except Exception as e:
            print(f"[ERROR] {ip}:{port} {e}")
            break

    print(f"[INFO] Stopped receiver for {ip}:{port}")
    sock.close()
    cv2.destroyWindow(f"{ip}:{port}")






import zmq
import msgpack
import cv2
import numpy as np
import threading
import time
import json
import os

# Path to the shared agent file
AGENTS_FILE = "/app/agent_instances.json"

# Configuration
display_window_size = 5
min_ready_frames = 3

frame_conter = 0
fps_timer = time.time()
context = zmq.Context()
frame_buffer = {}
expected_frame_id = 0

# Track running agent threads
started_detectors = {}  # {(ip, port): {"thread": Thread, "stop_event": Event}}


# Load agents from JSON file
def load_agents():
    try:
        with open(AGENTS_FILE, "r") as f:
            data = json.load(f)
            return [(d["ip"], d["port"]) for d in data]
    except Exception as e:
        print(f"[ERROR] Could not read {AGENTS_FILE}: {e}")
        return []


# Receive frames from one detector VM
def receive_from_vm(ip, port, stop_event):
    sock = context.socket(zmq.PULL)
    sock.connect(f"tcp://{ip}:{port}")
    print(f"[INFO] Connected to detector at {ip}:{port}")
    
    while not stop_event.is_set():
        try:
            msg = sock.recv(flags=zmq.NOBLOCK)
            data = msgpack.unpackb(msg, raw=False)
            frame_id = data["frame_id"]
            jpg = data["image"]
            print(f"frame id :{frame_id} with size: {len(msg)} received from VM {ip}")
            frame = cv2.imdecode(np.frombuffer(jpg, np.uint8), cv2.IMREAD_COLOR)
            if frame is not None:
                frame_buffer[frame_id] = frame
        except zmq.Again:
            time.sleep(0.01)
        except Exception as e:
            print(f"[ERROR] {ip}:{port} {e}")
            break

    print(f"[INFO] Stopped receiver for {ip}:{port}")
    sock.close()
    cv2.destroyWindow(f"{ip}:{port}")


# Watch for changes in the agent list and manage threads
def watch_for_new_agents():
    while True:
        agents = load_agents()
        current_set = set(agents)
        known_set = set(started_detectors.keys())

        # Stop removed agents
        removed_agents = known_set - current_set
        for agent in removed_agents:
            print(f"[INFO] Stopping thread for {agent[0]}:{agent[1]}")
            started_detectors[agent]["stop_event"].set()
            started_detectors[agent]["thread"].join()
            del started_detectors[agent]

        # Start new agents
        for ip, port in current_set - known_set:
            print(f"[INFO] Starting thread for {ip}:{port}")
            stop_event = threading.Event()
            thread = threading.Thread(target=receive_from_vm, args=(ip, port, stop_event), daemon=True)
            thread.start()
            started_detectors[(ip, port)] = {"thread": thread, "stop_event": stop_event}

        time.sleep(3)


# Start monitoring thread
threading.Thread(target=watch_for_new_agents, daemon=True).start()

# OpenCV display loop
cv2.namedWindow("YOLOv5 Reconstructed", cv2.WINDOW_NORMAL)
cv2.resizeWindow("YOLOv5 Reconstructed", 960, 540)

try:
    while True:
        if len(frame_buffer) >= min_ready_frames:
            sorted_ids = sorted(frame_buffer.keys())
            to_display = sorted_ids[:display_window_size]
            for fid in to_display:
                frame = frame_buffer.pop(fid)
                cv2.imshow("YOLOv5 Reconstructed", frame)
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    raise KeyboardInterrupt
        time.sleep(0.01)
except KeyboardInterrupt:
    print("\n[SHUTDOWN] Stopping all threads...")
    for agent in list(started_detectors.keys()):
        started_detectors[agent]["stop_event"].set()
    for agent in list(started_detectors.keys()):
        started_detectors[agent]["thread"].join()
    print("[SHUTDOWN] Viewer closed.")

cv2.destroyAllWindows()
